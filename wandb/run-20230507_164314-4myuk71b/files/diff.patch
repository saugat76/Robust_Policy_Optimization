diff --git a/rpo_continuous_action.py b/rpo_continuous_action.py
index 14fb922..12cf772 100644
--- a/rpo_continuous_action.py
+++ b/rpo_continuous_action.py
@@ -74,7 +74,7 @@ def parse_args():
         help="the alpha parameter for RPO")
     parser.add_argument("--num-nodes", type=float, default=64,
         help="number of nodes used for actor and critic n/w")
-    parser.add_argument("--activation-func", type=str, default="Tanh",
+    parser.add_argument("--activation-func", type=str, default="nn.Tanh()",
         help="activation function used in actor and critic n/w: 'nn.ReLu()', 'nn.Tanh()', 'nn.Sigmoid()'")
     
     
@@ -174,8 +174,8 @@ sweep_configuration = {
     'batch_size': {'values': [16, 32, 64]},
     'lr': {'max': 0.1, 'min': 0.0001},
     'num_nodes': {'values': [64, 128, 256]},
-    'optimizer_choices': {'values': ['Adam', 'RMSProp', 'AdamW']}, 
-    'activation_funcs': {'values': [nn.ReLu(), nn.Tanh(), nn.Sigmoid()]}
+    'optimizer_choices': {'values': ["Adam", "RMSProp", "AdamW"]}, 
+    'activation_funcs': {'values': ["ReLU()", "nn.Tanh()", "nn.Sigmoid()"]}
     
     }
 }
@@ -190,7 +190,7 @@ def main():
     # May use wandb to do hyperparameter tunning and evaluate the model performance 
     run_name = f"{args.env_id}__{args.exp_name}__{args.seed}__{int(time.time())}"
     if args.track:
-        wandb.init(
+        run = wandb.init(
             project=args.wandb_project_name,
             entity=args.wandb_entity,
             sync_tensorboard=True,
@@ -202,7 +202,7 @@ def main():
         args.learning_rate = wandb.config.lr
         args.batch_size = wandb.config.batch_size
         args.num_nodes = wandb.config.num_nodes
-        optimizer_choice = wandb.config.optimizer
+        optimizer_choice = wandb.config.optimizer_choices
         args.activation_func = wandb.config.activation_funcs 
         
     writer = SummaryWriter(f"runs/{run_name}")
@@ -222,6 +222,15 @@ def main():
         [make_env(args.env_id, i, args.capture_video, run_name, args.gamma) for i in range(args.num_envs)]
     )
     assert isinstance(envs.single_action_space, gym.spaces.Box), "only continuous action space is supported"
+    
+    # Added by Saugat 
+    # Since the functions are not serializable so, using if else to select the respective activation function
+    if args.activation_func  == "nn.ReLU()":
+        activation_func = nn.ReLU()
+    elif args.activation_func  == "nn.Tanh()":
+        activation_func = nn.Tanh()
+    elif args.activation_func == "nn.Sigmoid()":
+        activation_func = nn.Sigmoid() 
 
     agent = Agent(envs, args.rpo_alpha, args.num_nodes, args.activation_func).to(device)
 
@@ -400,10 +409,12 @@ def main():
                     video_filenames.add(filename)
 
     envs.close()
+    wandb.finish()
     writer.close()
 
 
 ## Addition by Saugat for implementation in notebook 
 # Sweep the code // main function usign the sweep configuration 
 # For the implemntation // running in CLI ->   wandb agent sweep_id
-# wandb.agent(sweep_id=sweep_id, function=main)
\ No newline at end of file
+# wandb.agent(sweep_id=sweep_id, function=main)
+wandb.agent(sweep_id, function=main, count=5)
\ No newline at end of file
